{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# prompt: import dataset from google drive\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the path to your dataset zip file in Google Drive\n",
        "zip_file_path = '/content/battery_dataset.zip'  # Replace with your actual path\n",
        "\n",
        "# Ensure the directory exists\n",
        "os.makedirs('/content/', exist_ok=True)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TC06DdD8h-ei",
        "outputId": "eb31656a-5b39-4481-87f9-bbb06686c195"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract files from the zip archive\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')"
      ],
      "metadata": {
        "id": "flun2jTe8jHy"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "def split_batteries(battery_ids, n_val=6, random_state=None):\n",
        "    \"\"\"\n",
        "    Randomly split battery IDs into training and validation sets\n",
        "\n",
        "    Args:\n",
        "        battery_ids: List of all battery IDs\n",
        "        n_val: Number of batteries for validation\n",
        "        random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        train_battery_ids, val_battery_ids\n",
        "    \"\"\"\n",
        "    if random_state is not None:\n",
        "        np.random.seed(random_state)\n",
        "\n",
        "    battery_ids = np.array(battery_ids)\n",
        "    val_indices = np.random.choice(len(battery_ids), size=n_val, replace=False)\n",
        "    val_battery_ids = battery_ids[val_indices]\n",
        "    train_battery_ids = np.array([bid for bid in battery_ids if bid not in val_battery_ids])\n",
        "\n",
        "    print(f\"Training batteries ({len(train_battery_ids)}): {', '.join(train_battery_ids)}\")\n",
        "    print(f\"Validation batteries ({len(val_battery_ids)}): {', '.join(val_battery_ids)}\")\n",
        "\n",
        "    return train_battery_ids, val_battery_ids\n",
        "\n",
        "def parse_start_time(time_array):\n",
        "    \"\"\"Convert the time array to datetime\"\"\"\n",
        "    try:\n",
        "        return pd.Timestamp(year=int(time_array[0]),\n",
        "                          month=int(time_array[1]),\n",
        "                          day=int(time_array[2]),\n",
        "                          hour=int(time_array[3]),\n",
        "                          minute=int(time_array[4]),\n",
        "                          second=int(time_array[5]))\n",
        "    except:\n",
        "        return pd.NaT\n",
        "\n",
        "def load_metadata(metadata_path, battery_ids=None):\n",
        "    \"\"\"\n",
        "    Load and process metadata file\n",
        "\n",
        "    Args:\n",
        "        metadata_path: Path to metadata file\n",
        "        battery_ids: Optional list of battery IDs to filter\n",
        "    \"\"\"\n",
        "    # Read metadata\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "    # Filter for specified batteries if provided\n",
        "    if battery_ids is not None:\n",
        "        metadata = metadata[metadata['battery_id'].isin(battery_ids)]\n",
        "\n",
        "    # Convert start_time from string to list of numbers\n",
        "    metadata['start_time'] = metadata['start_time'].apply(\n",
        "        lambda x: [float(num) for num in x.strip('[]').split()]\n",
        "    )\n",
        "\n",
        "    # Convert to datetime\n",
        "    metadata['datetime'] = metadata['start_time'].apply(parse_start_time)\n",
        "\n",
        "    # Keep only discharge cycles\n",
        "    discharge_data = metadata[metadata['type'] == 'discharge'].copy()\n",
        "\n",
        "    # Sort by battery_id and datetime\n",
        "    discharge_data = discharge_data.sort_values(['battery_id', 'datetime'])\n",
        "\n",
        "    # Add cycle number for each battery\n",
        "    discharge_data['cycle_number'] = discharge_data.groupby('battery_id').cumcount() + 1\n",
        "\n",
        "    return discharge_data\n",
        "\n",
        "def load_cycle_data(filename, data_folder):\n",
        "    \"\"\"Load individual cycle file and extract relevant features\"\"\"\n",
        "    try:\n",
        "        # Load the cycle file\n",
        "        cycle_path = os.path.join(data_folder, filename)\n",
        "        cycle_data = pd.read_csv(cycle_path)\n",
        "\n",
        "        # Extract relevant features\n",
        "        features = {\n",
        "            'voltage_min': cycle_data['Voltage_measured'].min(),\n",
        "            'voltage_max': cycle_data['Voltage_measured'].max(),\n",
        "            'voltage_mean': cycle_data['Voltage_measured'].mean(),\n",
        "            'current_mean': cycle_data['Current_measured'].mean(),\n",
        "            'temperature_max': cycle_data['Temperature_measured'].max(),\n",
        "            'temperature_mean': cycle_data['Temperature_measured'].mean(),\n",
        "            'discharge_time': cycle_data['Time'].max()  # Total discharge time\n",
        "        }\n",
        "\n",
        "        return features\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {filename}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def add_engineered_features(df):\n",
        "    \"\"\"Add engineered features for SOH prediction\"\"\"\n",
        "    # Group by battery_id for calculations\n",
        "    for battery_id in df['battery_id'].unique():\n",
        "        battery_mask = df['battery_id'] == battery_id\n",
        "\n",
        "        # Calculate rolling statistics (3, 5, 10 cycles)\n",
        "        for window in [3, 5, 10]:\n",
        "            # Capacity features\n",
        "            df.loc[battery_mask, f'capacity_mean_{window}'] = df.loc[battery_mask, 'capacity'].rolling(window, min_periods=1).mean().shift(1)\n",
        "            df.loc[battery_mask, f'capacity_std_{window}'] = df.loc[battery_mask, 'capacity'].rolling(window, min_periods=1).std().shift(1)\n",
        "\n",
        "            # Voltage features\n",
        "            df.loc[battery_mask, f'voltage_mean_{window}'] = df.loc[battery_mask, 'voltage_mean'].rolling(window, min_periods=1).mean().shift(1)\n",
        "\n",
        "            # Temperature features\n",
        "            df.loc[battery_mask, f'temperature_mean_{window}'] = df.loc[battery_mask, 'temperature_mean'].rolling(window, min_periods=1).mean().shift(1)\n",
        "\n",
        "        # Calculate degradation rates\n",
        "        df.loc[battery_mask, 'capacity_rate'] = df.loc[battery_mask, 'capacity'].pct_change()\n",
        "\n",
        "        # Calculate difference from initial capacity\n",
        "        initial_capacity = df.loc[battery_mask, 'capacity'].iloc[0]\n",
        "        df.loc[battery_mask, 'capacity_pct_initial'] = (df.loc[battery_mask, 'capacity'] / initial_capacity) * 100\n",
        "\n",
        "    return df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J34_r-belWoa"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''def create_battery_dataset(metadata_path, data_folder, battery_ids, max_files=None):\n",
        "    \"\"\"\n",
        "    Create dataset for specified batteries only\n",
        "\n",
        "    Args:\n",
        "        metadata_path: Path to metadata file\n",
        "        data_folder: Path to cycle data folder\n",
        "        battery_ids: List of battery IDs to include\n",
        "        max_files: Optional limit on number of files to process\n",
        "    \"\"\"\n",
        "    print(f\"Loading metadata for batteries: {', '.join(battery_ids)}\")\n",
        "    discharge_data = load_metadata(metadata_path, battery_ids)\n",
        "\n",
        "    if max_files:\n",
        "        discharge_data = discharge_data.head(max_files)\n",
        "\n",
        "    print(\"Processing cycle files...\")\n",
        "    # Initialize lists to store data\n",
        "    processed_data = []\n",
        "\n",
        "    # Process each discharge cycle\n",
        "    for _, row in tqdm(discharge_data.iterrows(), total=len(discharge_data)):\n",
        "        cycle_features = load_cycle_data(row['filename'], data_folder)\n",
        "\n",
        "        if cycle_features is not None:\n",
        "            # Combine metadata with cycle features\n",
        "            cycle_data = {\n",
        "                'battery_id': row['battery_id'],\n",
        "                'cycle_number': row['cycle_number'],\n",
        "                'ambient_temperature': row['ambient_temperature'],\n",
        "                'capacity': row['Capacity'],\n",
        "                'datetime': row['datetime'],\n",
        "                **cycle_features\n",
        "            }\n",
        "            processed_data.append(cycle_data)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(processed_data)\n",
        "\n",
        "    # Convert 'capacity' column to numeric\n",
        "    df['capacity'] = pd.to_numeric(df['capacity'], errors='coerce')\n",
        "\n",
        "    # Calculate SOH\n",
        "    rated_capacity = 2.0  # Ah\n",
        "    df['SOH'] = (df['capacity'] / rated_capacity) * 100\n",
        "\n",
        "    # Add engineered features\n",
        "    df = add_engineered_features(df)\n",
        "\n",
        "    return df\n",
        "'''\n"
      ],
      "metadata": {
        "id": "LqmEf9Mr2cop"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''def main(metadata_path, data_folder, random_state=42):\n",
        "    \"\"\"\n",
        "    Main function to create train and validation datasets\n",
        "\n",
        "    Args:\n",
        "        metadata_path: Path to metadata file\n",
        "        data_folder: Path to cycle data folder\n",
        "        random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        train_df, val_df: Training and validation datasets\n",
        "    \"\"\"\n",
        "    # All battery IDs\n",
        "    all_battery_ids = ['B0005', 'B0006', 'B0007', 'B0018', 'B0025', 'B0026', 'B0027', 'B0028',\n",
        "                      'B0029', 'B0030', 'B0031', 'B0032', 'B0033', 'B0034', 'B0036', 'B0038',\n",
        "                      'B0039', 'B0040', 'B0041', 'B0042', 'B0043', 'B0044', 'B0045', 'B0046',\n",
        "                      'B0047', 'B0048', 'B0049', 'B0050', 'B0051', 'B0052', 'B0053', 'B0054',\n",
        "                      'B0055', 'B0056']\n",
        "\n",
        "    # Split batteries into train and validation sets\n",
        "    train_battery_ids, val_battery_ids = split_batteries(all_battery_ids, n_val=6, random_state=random_state)\n",
        "\n",
        "    # Create training dataset\n",
        "    print(\"\\nCreating training dataset...\")\n",
        "    train_df = create_battery_dataset(metadata_path, data_folder, train_battery_ids)\n",
        "\n",
        "    # Create validation dataset\n",
        "    print(\"\\nCreating validation dataset...\")\n",
        "    val_df = create_battery_dataset(metadata_path, data_folder, val_battery_ids)\n",
        "\n",
        "    return train_df, val_df\n",
        "'''\n",
        "\n"
      ],
      "metadata": {
        "id": "SYxQnYw32gRu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_batteries(battery_ids, n_val=6, random_state=42):\n",
        "    \"\"\"\n",
        "    Stratified split of batteries ensuring representative validation set\n",
        "\n",
        "    Args:\n",
        "        battery_ids: List of all battery IDs\n",
        "        n_val: Number of batteries for validation\n",
        "        random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        train_battery_ids, val_battery_ids\n",
        "    \"\"\"\n",
        "    # First, load metadata to get initial information about batteries\n",
        "    metadata = pd.read_csv(metadata_path)\n",
        "\n",
        "    # Calculate initial metrics for each battery\n",
        "    battery_metrics = []\n",
        "    for battery_id in battery_ids:\n",
        "        battery_data = metadata[metadata['battery_id'] == battery_id]\n",
        "\n",
        "        metrics = {\n",
        "            'battery_id': battery_id,\n",
        "            'total_cycles': len(battery_data),\n",
        "            'initial_capacity': battery_data['Capacity'].iloc[0],\n",
        "            'final_capacity': battery_data['Capacity'].iloc[-1]\n",
        "        }\n",
        "        battery_metrics.append(metrics)\n",
        "\n",
        "    # Convert to DataFrame for easier manipulation\n",
        "    battery_metrics_df = pd.DataFrame(battery_metrics)\n",
        "\n",
        "    # Sort batteries by total cycles to ensure spread\n",
        "    battery_metrics_df = battery_metrics_df.sort_values('total_cycles')\n",
        "\n",
        "    # Stratified split considering multiple factors\n",
        "    np.random.seed(random_state)\n",
        "    val_battery_ids = []\n",
        "\n",
        "    # Ensure validation set captures variety\n",
        "    while len(val_battery_ids) < n_val:\n",
        "        # Select a battery with a mix of characteristics\n",
        "        candidates = [\n",
        "            bat for bat in battery_metrics_df['battery_id']\n",
        "            if bat not in val_battery_ids\n",
        "        ]\n",
        "\n",
        "        if not candidates:\n",
        "            break\n",
        "\n",
        "        # Select battery with median characteristics\n",
        "        selected_battery = candidates[len(candidates) // 2]\n",
        "        val_battery_ids.append(selected_battery)\n",
        "\n",
        "    # Remaining batteries go to training\n",
        "    train_battery_ids = [\n",
        "        bat for bat in battery_ids\n",
        "        if bat not in val_battery_ids\n",
        "    ]\n",
        "\n",
        "    print(\"Validation Batteries:\", val_battery_ids)\n",
        "    print(\"Training Batteries:\", train_battery_ids)\n",
        "\n",
        "    return train_battery_ids, val_battery_ids\n",
        "\n",
        "def create_battery_dataset(metadata_path, data_folder, battery_ids, max_files=None):\n",
        "    \"\"\"\n",
        "    Create dataset for specified batteries with enhanced preprocessing\n",
        "\n",
        "    Args:\n",
        "        metadata_path: Path to metadata file\n",
        "        data_folder: Path to cycle data folder\n",
        "        battery_ids: List of battery IDs to include\n",
        "        max_files: Optional limit on number of files to process\n",
        "\n",
        "    Returns:\n",
        "        Processed DataFrame with engineered features\n",
        "    \"\"\"\n",
        "    print(f\"Loading metadata for batteries: {', '.join(battery_ids)}\")\n",
        "\n",
        "    # Load metadata filtered for specified batteries\n",
        "    discharge_data = load_metadata(metadata_path, battery_ids)\n",
        "\n",
        "    # Optional file limit\n",
        "    if max_files:\n",
        "        discharge_data = discharge_data.head(max_files)\n",
        "\n",
        "    print(f\"Processing {len(discharge_data)} discharge cycles...\")\n",
        "    processed_data = []\n",
        "\n",
        "    # Process each discharge cycle\n",
        "    for _, row in tqdm(discharge_data.iterrows(), total=len(discharge_data)):\n",
        "        cycle_features = load_cycle_data(row['filename'], data_folder)\n",
        "\n",
        "        if cycle_features is not None:\n",
        "            cycle_data = {\n",
        "                'battery_id': row['battery_id'],\n",
        "                'cycle_number': row['cycle_number'],\n",
        "                'ambient_temperature': row['ambient_temperature'],\n",
        "                'capacity': row['Capacity'],\n",
        "                'datetime': row['datetime'],\n",
        "                **cycle_features\n",
        "            }\n",
        "            processed_data.append(cycle_data)\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(processed_data)\n",
        "\n",
        "    # Rigorous numeric conversion and cleaning\n",
        "    df['capacity'] = pd.to_numeric(df['capacity'], errors='coerce')\n",
        "    df.dropna(subset=['capacity'], inplace=True)\n",
        "\n",
        "    # SOH calculation with more robust approach\n",
        "    rated_capacities = {\n",
        "        'B0005': 2.0,  # Example, replace with actual rated capacities\n",
        "        'B0006': 2.0,\n",
        "        'B0007': 2.0,\n",
        "        'B0018': 2.0,\n",
        "        'B0025': 2.0,\n",
        "        'B0026': 2.0,\n",
        "        'B0027': 2.0,\n",
        "        'B0028': 2.0,\n",
        "        'B0029': 2.0,\n",
        "        'B0030': 2.0,\n",
        "        'B0031': 2.0,\n",
        "        'B0032': 2.0,\n",
        "        'B0033': 2.0,\n",
        "        'B0034': 2.0,\n",
        "        'B0036': 2.0,\n",
        "        'B0038': 2.0,\n",
        "        'B0039': 2.0,\n",
        "        'B0040': 2.0,\n",
        "        'B0041': 2.0,\n",
        "        'B0042': 2.0,\n",
        "        'B0043': 2.0,\n",
        "        'B0044': 2.0,\n",
        "        'B0045': 2.0,\n",
        "        'B0046': 2.0,\n",
        "        'B0047': 2.0,\n",
        "        'B0048': 2.0,\n",
        "        'B0049': 2.0,\n",
        "        'B0050': 2.0,\n",
        "        'B0051': 2.0,\n",
        "        'B0052': 2.0,\n",
        "        'B0053': 2.0,\n",
        "        'B0054': 2.0,\n",
        "        'B0055': 2.0,\n",
        "        'B0056': 2.0\n",
        "        # Add more battery-specific rated capacities\n",
        "    }\n",
        "\n",
        "    def calculate_soh(row):\n",
        "        rated_cap = rated_capacities.get(row['battery_id'], 2.0)  # Default 2.0 if not specified\n",
        "        return (row['capacity'] / rated_cap) * 100\n",
        "\n",
        "    df['SOH'] = df.apply(calculate_soh, axis=1)\n",
        "\n",
        "    # Perform feature engineering\n",
        "    df = add_engineered_features(df)\n",
        "\n",
        "    # Sort by battery and cycle number\n",
        "    df.sort_values(['battery_id', 'cycle_number'], inplace=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "def main(metadata_path, data_folder, random_state=42):\n",
        "    \"\"\"\n",
        "    Main function to create train and validation datasets\n",
        "\n",
        "    Args:\n",
        "        metadata_path: Path to metadata file\n",
        "        data_folder: Path to cycle data folder\n",
        "        random_state: Random seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        train_df, val_df: Training and validation datasets\n",
        "    \"\"\"\n",
        "    # All battery IDs\n",
        "    all_battery_ids = ['B0005', 'B0006', 'B0007', 'B0018', 'B0025', 'B0026', 'B0027', 'B0028',\n",
        "                      'B0029', 'B0030', 'B0031', 'B0032', 'B0033', 'B0034', 'B0036', 'B0038',\n",
        "                      'B0039', 'B0040', 'B0041', 'B0042', 'B0043', 'B0044', 'B0045', 'B0046',\n",
        "                      'B0047', 'B0048', 'B0049', 'B0050', 'B0051', 'B0052', 'B0053', 'B0054',\n",
        "                      'B0055', 'B0056']  # Your complete list\n",
        "\n",
        "    # Split batteries\n",
        "    train_battery_ids, val_battery_ids = split_batteries(\n",
        "        all_battery_ids,\n",
        "        n_val=6,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    print(\"\\nCreating training dataset...\")\n",
        "    train_df = create_battery_dataset(metadata_path, data_folder, train_battery_ids)\n",
        "\n",
        "    print(\"\\nCreating validation dataset...\")\n",
        "    val_df = create_battery_dataset(metadata_path, data_folder, val_battery_ids)\n",
        "\n",
        "    return train_df, val_df"
      ],
      "metadata": {
        "id": "1DWxU0NZZWvB"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    metadata_path = \"/content/cleaned_dataset/metadata.csv\"\n",
        "    data_folder = \"/content/cleaned_dataset/data/\"\n",
        "\n",
        "    train_df, val_df = main(metadata_path, data_folder)\n",
        "\n",
        "    print(\"\\nDataset shapes:\")\n",
        "    print(f\"Training set: {train_df.shape}\")\n",
        "    print(f\"Validation set: {val_df.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb3TopfU2h13",
        "outputId": "d0712756-e193-486a-8e79-60fb43402442"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Batteries: ['B0046', 'B0041', 'B0047', 'B0053', 'B0048', 'B0039']\n",
            "Training Batteries: ['B0005', 'B0006', 'B0007', 'B0018', 'B0025', 'B0026', 'B0027', 'B0028', 'B0029', 'B0030', 'B0031', 'B0032', 'B0033', 'B0034', 'B0036', 'B0038', 'B0040', 'B0042', 'B0043', 'B0044', 'B0045', 'B0049', 'B0050', 'B0051', 'B0052', 'B0054', 'B0055', 'B0056']\n",
            "\n",
            "Creating training dataset...\n",
            "Loading metadata for batteries: B0005, B0006, B0007, B0018, B0025, B0026, B0027, B0028, B0029, B0030, B0031, B0032, B0033, B0034, B0036, B0038, B0040, B0042, B0043, B0044, B0045, B0049, B0050, B0051, B0052, B0054, B0055, B0056\n",
            "Processing 2408 discharge cycles...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2408/2408 [00:05<00:00, 414.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Creating validation dataset...\n",
            "Loading metadata for batteries: B0046, B0041, B0047, B0053, B0048, B0039\n",
            "Processing 386 discharge cycles...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 386/386 [00:00<00:00, 491.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset shapes:\n",
            "Training set: (2383, 13)\n",
            "Validation set: (386, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['battery_id'].nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5fR_afZvLAw",
        "outputId": "19e48f72-b6da-4c77-ca25-f17dabb2418e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "xe3pkZ-7TI8b",
        "outputId": "fa1db511-dcf7-4525-8f64-655fb761ab09"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  battery_id  cycle_number  ambient_temperature  capacity            datetime  \\\n",
              "0      B0005             1                   24  1.856487 2008-04-02 15:25:41   \n",
              "1      B0005             2                   24  1.846327 2008-04-02 19:43:48   \n",
              "2      B0005             3                   24  1.835349 2008-04-03 00:01:06   \n",
              "3      B0005             4                   24  1.835263 2008-04-03 04:16:37   \n",
              "4      B0005             5                   24  1.834646 2008-04-03 08:33:25   \n",
              "\n",
              "   voltage_min  voltage_max  voltage_mean  current_mean  temperature_max  \\\n",
              "0     2.612467     4.191492      3.529829     -1.818702        38.982181   \n",
              "1     2.587209     4.189773      3.537320     -1.817560        39.033398   \n",
              "2     2.651917     4.188187      3.543737     -1.816487        38.818797   \n",
              "3     2.592948     4.188461      3.543666     -1.825589        38.762305   \n",
              "4     2.547420     4.188299      3.542343     -1.826114        38.665393   \n",
              "\n",
              "   temperature_mean  discharge_time        SOH  \n",
              "0         32.572328        3690.234  92.824371  \n",
              "1         32.725235        3672.344  92.316362  \n",
              "2         32.642862        3651.641  91.767460  \n",
              "3         32.514876        3631.563  91.763126  \n",
              "4         32.382349        3629.172  91.732275  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ebb79944-88d2-4d20-8d75-52af69b8c8f9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_id</th>\n",
              "      <th>cycle_number</th>\n",
              "      <th>ambient_temperature</th>\n",
              "      <th>capacity</th>\n",
              "      <th>datetime</th>\n",
              "      <th>voltage_min</th>\n",
              "      <th>voltage_max</th>\n",
              "      <th>voltage_mean</th>\n",
              "      <th>current_mean</th>\n",
              "      <th>temperature_max</th>\n",
              "      <th>temperature_mean</th>\n",
              "      <th>discharge_time</th>\n",
              "      <th>SOH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0005</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>1.856487</td>\n",
              "      <td>2008-04-02 15:25:41</td>\n",
              "      <td>2.612467</td>\n",
              "      <td>4.191492</td>\n",
              "      <td>3.529829</td>\n",
              "      <td>-1.818702</td>\n",
              "      <td>38.982181</td>\n",
              "      <td>32.572328</td>\n",
              "      <td>3690.234</td>\n",
              "      <td>92.824371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B0005</td>\n",
              "      <td>2</td>\n",
              "      <td>24</td>\n",
              "      <td>1.846327</td>\n",
              "      <td>2008-04-02 19:43:48</td>\n",
              "      <td>2.587209</td>\n",
              "      <td>4.189773</td>\n",
              "      <td>3.537320</td>\n",
              "      <td>-1.817560</td>\n",
              "      <td>39.033398</td>\n",
              "      <td>32.725235</td>\n",
              "      <td>3672.344</td>\n",
              "      <td>92.316362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B0005</td>\n",
              "      <td>3</td>\n",
              "      <td>24</td>\n",
              "      <td>1.835349</td>\n",
              "      <td>2008-04-03 00:01:06</td>\n",
              "      <td>2.651917</td>\n",
              "      <td>4.188187</td>\n",
              "      <td>3.543737</td>\n",
              "      <td>-1.816487</td>\n",
              "      <td>38.818797</td>\n",
              "      <td>32.642862</td>\n",
              "      <td>3651.641</td>\n",
              "      <td>91.767460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B0005</td>\n",
              "      <td>4</td>\n",
              "      <td>24</td>\n",
              "      <td>1.835263</td>\n",
              "      <td>2008-04-03 04:16:37</td>\n",
              "      <td>2.592948</td>\n",
              "      <td>4.188461</td>\n",
              "      <td>3.543666</td>\n",
              "      <td>-1.825589</td>\n",
              "      <td>38.762305</td>\n",
              "      <td>32.514876</td>\n",
              "      <td>3631.563</td>\n",
              "      <td>91.763126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B0005</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>1.834646</td>\n",
              "      <td>2008-04-03 08:33:25</td>\n",
              "      <td>2.547420</td>\n",
              "      <td>4.188299</td>\n",
              "      <td>3.542343</td>\n",
              "      <td>-1.826114</td>\n",
              "      <td>38.665393</td>\n",
              "      <td>32.382349</td>\n",
              "      <td>3629.172</td>\n",
              "      <td>91.732275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ebb79944-88d2-4d20-8d75-52af69b8c8f9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ebb79944-88d2-4d20-8d75-52af69b8c8f9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ebb79944-88d2-4d20-8d75-52af69b8c8f9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7db8ee2c-5678-4570-b717-6132e26fb0d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7db8ee2c-5678-4570-b717-6132e26fb0d5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7db8ee2c-5678-4570-b717-6132e26fb0d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 2383,\n  \"fields\": [\n    {\n      \"column\": \"battery_id\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 28,\n        \"samples\": [\n          \"B0030\",\n          \"B0054\",\n          \"B0029\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cycle_number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 50,\n        \"min\": 1,\n        \"max\": 197,\n        \"num_unique_values\": 197,\n        \"samples\": [\n          141,\n          114,\n          17\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ambient_temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 4,\n        \"max\": 44,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          43,\n          4,\n          44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"capacity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45832189772522397,\n        \"min\": 0.0,\n        \"max\": 2.6401491157387014,\n        \"num_unique_values\": 2375,\n        \"samples\": [\n          0.8025719464987874,\n          1.314290971597844,\n          1.480413677976106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"datetime\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2008-04-02 15:25:41\",\n        \"max\": \"2010-09-30 15:32:33\",\n        \"num_unique_values\": 924,\n        \"samples\": [\n          \"2009-03-05 23:20:01\",\n          \"2010-09-12 20:07:24\",\n          \"2008-04-22 15:33:49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"voltage_min\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3049666783104767,\n        \"min\": 0.1927377074618698,\n        \"max\": 3.83839582745546,\n        \"num_unique_values\": 2383,\n        \"samples\": [\n          2.1908121182442706,\n          2.6927360739353285,\n          2.399740066713552\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"voltage_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.03941824033628541,\n        \"min\": 3.6772190710694974,\n        \"max\": 4.542426686314755,\n        \"num_unique_values\": 2383,\n        \"samples\": [\n          4.202670619155847,\n          4.181791330814548,\n          4.204756646870948\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"voltage_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19036708815132528,\n        \"min\": 2.5300104336765608,\n        \"max\": 4.452558225780352,\n        \"num_unique_values\": 2383,\n        \"samples\": [\n          3.480518309485383,\n          3.341678704653779,\n          3.4940185374934947\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"current_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7696095382863672,\n        \"min\": -3.976472905870513,\n        \"max\": -0.029284266758646496,\n        \"num_unique_values\": 2383,\n        \"samples\": [\n          -1.8658259561850365,\n          -1.774352624864773,\n          -1.89408796703159\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature_max\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.287780412778172,\n        \"min\": 6.383481120383388,\n        \"max\": 69.86974573152932,\n        \"num_unique_values\": 2383,\n        \"samples\": [\n          40.73001188190229,\n          14.205466297575018,\n          36.35251788056927\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.900640393959817,\n        \"min\": 4.857763577409316,\n        \"max\": 58.954810986890266,\n        \"num_unique_values\": 2383,\n        \"samples\": [\n          32.637733704417855,\n          10.278021353580035,\n          30.05896964075817\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"discharge_time\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1283.8807633733027,\n        \"min\": 23.0,\n        \"max\": 6574.671,\n        \"num_unique_values\": 920,\n        \"samples\": [\n          6328.172,\n          3224.5,\n          2973.281\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SOH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 22.916094886261224,\n        \"min\": 0.0,\n        \"max\": 132.00745578693505,\n        \"num_unique_values\": 2375,\n        \"samples\": [\n          40.12859732493937,\n          65.7145485798922,\n          74.02068389880529\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.columns"
      ],
      "metadata": {
        "id": "hVhUgkh_WIkV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f5b27a3-7f00-4c32-93c3-c10910ee2bf6"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['battery_id', 'cycle_number', 'ambient_temperature', 'capacity',\n",
              "       'datetime', 'voltage_min', 'voltage_max', 'voltage_mean',\n",
              "       'current_mean', 'temperature_max', 'temperature_mean', 'discharge_time',\n",
              "       'SOH'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['battery_id'].nunique()"
      ],
      "metadata": {
        "id": "4cQ9pL8lWgtG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03c05df-869b-4923-cf4f-289b57a7558b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['SOH']"
      ],
      "metadata": {
        "id": "CPlvaHaZWPxT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "outputId": "8d5f5736-aee9-4c19-ffb4-eb8b78d610bf"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       92.824371\n",
              "1       92.316362\n",
              "2       91.767460\n",
              "3       91.763126\n",
              "4       91.732275\n",
              "          ...    \n",
              "2403    56.510957\n",
              "2404    56.293597\n",
              "2405    57.150541\n",
              "2406    56.863659\n",
              "2407    56.452951\n",
              "Name: SOH, Length: 2383, dtype: float64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SOH</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>92.824371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>92.316362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>91.767460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>91.763126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91.732275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2403</th>\n",
              "      <td>56.510957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2404</th>\n",
              "      <td>56.293597</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2405</th>\n",
              "      <td>57.150541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2406</th>\n",
              "      <td>56.863659</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2407</th>\n",
              "      <td>56.452951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2383 rows × 1 columns</p>\n",
              "</div><br><label><b>dtype:</b> float64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe().T"
      ],
      "metadata": {
        "id": "nt6yr_kHVgxX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "outputId": "db51e259-0bb9-474a-a09d-e4774e374b3d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      count                           mean  \\\n",
              "cycle_number         2383.0                      65.211918   \n",
              "ambient_temperature  2383.0                      20.161981   \n",
              "capacity             2383.0                       1.368017   \n",
              "datetime               2383  2009-07-31 20:51:03.386487808   \n",
              "voltage_min          2383.0                       2.322313   \n",
              "voltage_max          2383.0                        4.18622   \n",
              "voltage_mean         2383.0                       3.431155   \n",
              "current_mean         2383.0                       -1.83261   \n",
              "temperature_max      2383.0                      37.187487   \n",
              "temperature_mean     2383.0                      29.165898   \n",
              "discharge_time       2383.0                    3098.924818   \n",
              "SOH                  2383.0                      68.400849   \n",
              "\n",
              "                                     min                         25%  \\\n",
              "cycle_number                         1.0                        22.0   \n",
              "ambient_temperature                  4.0                         4.0   \n",
              "capacity                             0.0                    1.209136   \n",
              "datetime             2008-04-02 15:25:41  2008-08-09 01:45:33.500000   \n",
              "voltage_min                     0.192738                    2.089385   \n",
              "voltage_max                     3.677219                    4.182461   \n",
              "voltage_mean                     2.53001                    3.370423   \n",
              "current_mean                   -3.976473                   -1.960844   \n",
              "temperature_max                 6.383481                   24.256223   \n",
              "temperature_mean                4.857764                   14.170293   \n",
              "discharge_time                      23.0                   2545.8285   \n",
              "SOH                                  0.0                   60.456808   \n",
              "\n",
              "                                     50%                  75%  \\\n",
              "cycle_number                        54.0                 98.5   \n",
              "ambient_temperature                 24.0                 24.0   \n",
              "capacity                        1.472248             1.695568   \n",
              "datetime             2009-07-28 06:15:44  2010-06-19 05:42:11   \n",
              "voltage_min                     2.381438              2.62664   \n",
              "voltage_max                     4.187148              4.19796   \n",
              "voltage_mean                    3.421761             3.493673   \n",
              "current_mean                    -1.81882            -1.675116   \n",
              "temperature_max                 38.67192            49.007244   \n",
              "temperature_mean               31.969088            37.265468   \n",
              "discharge_time                  3011.781             3229.781   \n",
              "SOH                            73.612401            84.778419   \n",
              "\n",
              "                                     max          std  \n",
              "cycle_number                       197.0    50.074403  \n",
              "ambient_temperature                 44.0    11.553357  \n",
              "capacity                        2.640149     0.458322  \n",
              "datetime             2010-09-30 15:32:33          NaN  \n",
              "voltage_min                     3.838396     0.304967  \n",
              "voltage_max                     4.542427     0.039418  \n",
              "voltage_mean                    4.452558     0.190367  \n",
              "current_mean                   -0.029284      0.76961  \n",
              "temperature_max                69.869746     15.28778  \n",
              "temperature_mean               58.954811     12.90064  \n",
              "discharge_time                  6574.671  1283.880763  \n",
              "SOH                           132.007456    22.916095  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47979403-b9ae-4c52-aec2-8e06372c8863\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "      <th>std</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>cycle_number</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>65.211918</td>\n",
              "      <td>1.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>98.5</td>\n",
              "      <td>197.0</td>\n",
              "      <td>50.074403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ambient_temperature</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>20.161981</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>11.553357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capacity</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>1.368017</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.209136</td>\n",
              "      <td>1.472248</td>\n",
              "      <td>1.695568</td>\n",
              "      <td>2.640149</td>\n",
              "      <td>0.458322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <td>2383</td>\n",
              "      <td>2009-07-31 20:51:03.386487808</td>\n",
              "      <td>2008-04-02 15:25:41</td>\n",
              "      <td>2008-08-09 01:45:33.500000</td>\n",
              "      <td>2009-07-28 06:15:44</td>\n",
              "      <td>2010-06-19 05:42:11</td>\n",
              "      <td>2010-09-30 15:32:33</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voltage_min</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>2.322313</td>\n",
              "      <td>0.192738</td>\n",
              "      <td>2.089385</td>\n",
              "      <td>2.381438</td>\n",
              "      <td>2.62664</td>\n",
              "      <td>3.838396</td>\n",
              "      <td>0.304967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voltage_max</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>4.18622</td>\n",
              "      <td>3.677219</td>\n",
              "      <td>4.182461</td>\n",
              "      <td>4.187148</td>\n",
              "      <td>4.19796</td>\n",
              "      <td>4.542427</td>\n",
              "      <td>0.039418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voltage_mean</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>3.431155</td>\n",
              "      <td>2.53001</td>\n",
              "      <td>3.370423</td>\n",
              "      <td>3.421761</td>\n",
              "      <td>3.493673</td>\n",
              "      <td>4.452558</td>\n",
              "      <td>0.190367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>current_mean</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>-1.83261</td>\n",
              "      <td>-3.976473</td>\n",
              "      <td>-1.960844</td>\n",
              "      <td>-1.81882</td>\n",
              "      <td>-1.675116</td>\n",
              "      <td>-0.029284</td>\n",
              "      <td>0.76961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temperature_max</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>37.187487</td>\n",
              "      <td>6.383481</td>\n",
              "      <td>24.256223</td>\n",
              "      <td>38.67192</td>\n",
              "      <td>49.007244</td>\n",
              "      <td>69.869746</td>\n",
              "      <td>15.28778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temperature_mean</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>29.165898</td>\n",
              "      <td>4.857764</td>\n",
              "      <td>14.170293</td>\n",
              "      <td>31.969088</td>\n",
              "      <td>37.265468</td>\n",
              "      <td>58.954811</td>\n",
              "      <td>12.90064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>discharge_time</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>3098.924818</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2545.8285</td>\n",
              "      <td>3011.781</td>\n",
              "      <td>3229.781</td>\n",
              "      <td>6574.671</td>\n",
              "      <td>1283.880763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SOH</th>\n",
              "      <td>2383.0</td>\n",
              "      <td>68.400849</td>\n",
              "      <td>0.0</td>\n",
              "      <td>60.456808</td>\n",
              "      <td>73.612401</td>\n",
              "      <td>84.778419</td>\n",
              "      <td>132.007456</td>\n",
              "      <td>22.916095</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47979403-b9ae-4c52-aec2-8e06372c8863')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47979403-b9ae-4c52-aec2-8e06372c8863 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47979403-b9ae-4c52-aec2-8e06372c8863');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-483e07e5-b488-45eb-b944-5852db6d6212\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-483e07e5-b488-45eb-b944-5852db6d6212')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-483e07e5-b488-45eb-b944-5852db6d6212 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 2383.0,\n        \"max\": 2383.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2383.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1969-12-31 23:59:59.999999999\",\n        \"max\": \"2009-07-31 20:51:03.386487808\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          3098.924817876626\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"min\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1969-12-31 23:59:59.999999997\",\n        \"max\": \"2008-04-02 15:25:41\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          3.6772190710694974\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"25%\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1969-12-31 23:59:59.999999999\",\n        \"max\": \"2008-08-09 01:45:33.500000\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          2545.8285\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"50%\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1969-12-31 23:59:59.999999999\",\n        \"max\": \"2009-07-28 06:15:44\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          3011.781\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"75%\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1969-12-31 23:59:59.999999999\",\n        \"max\": \"2010-06-19 05:42:11\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          3229.7810000000027\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"max\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1970-01-01 00:00:00\",\n        \"max\": \"2010-09-30 15:32:33\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          6574.671\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"std\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": 0.03941824033628541,\n        \"max\": 1283.8807633733027,\n        \"num_unique_values\": 11,\n        \"samples\": [\n          0.19036708815132528\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: 3456789123\n",
        "\n",
        "train_df.info()"
      ],
      "metadata": {
        "id": "I79aJ0gH2-fs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a57d7e-053d-499d-fec5-b8607cf069d1"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 2383 entries, 0 to 2407\n",
            "Data columns (total 13 columns):\n",
            " #   Column               Non-Null Count  Dtype         \n",
            "---  ------               --------------  -----         \n",
            " 0   battery_id           2383 non-null   object        \n",
            " 1   cycle_number         2383 non-null   int64         \n",
            " 2   ambient_temperature  2383 non-null   int64         \n",
            " 3   capacity             2383 non-null   float64       \n",
            " 4   datetime             2383 non-null   datetime64[ns]\n",
            " 5   voltage_min          2383 non-null   float64       \n",
            " 6   voltage_max          2383 non-null   float64       \n",
            " 7   voltage_mean         2383 non-null   float64       \n",
            " 8   current_mean         2383 non-null   float64       \n",
            " 9   temperature_max      2383 non-null   float64       \n",
            " 10  temperature_mean     2383 non-null   float64       \n",
            " 11  discharge_time       2383 non-null   float64       \n",
            " 12  SOH                  2383 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(9), int64(2), object(1)\n",
            "memory usage: 260.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Drop all null values in df\n",
        "\n",
        "train_df = train_df.dropna()"
      ],
      "metadata": {
        "id": "3HnZj5mc3DV2"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.isnull().sum()"
      ],
      "metadata": {
        "id": "5n-ywD-g3G1l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 491
        },
        "outputId": "4fa109c2-1808-4d55-cec7-b82d50d019e0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "battery_id             0\n",
              "cycle_number           0\n",
              "ambient_temperature    0\n",
              "capacity               0\n",
              "datetime               0\n",
              "voltage_min            0\n",
              "voltage_max            0\n",
              "voltage_mean           0\n",
              "current_mean           0\n",
              "temperature_max        0\n",
              "temperature_mean       0\n",
              "discharge_time         0\n",
              "SOH                    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>battery_id</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cycle_number</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ambient_temperature</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>capacity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voltage_min</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voltage_max</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>voltage_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>current_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temperature_max</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>temperature_mean</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>discharge_time</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SOH</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import learning_curve\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "O0MYdyRk1Mc1"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    GridSearchCV,\n",
        "    KFold,\n",
        "    cross_val_score\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "import pickle\n",
        "\n",
        "\n",
        "class TrainDataSOHPredictor:\n",
        "    def __init__(self, train_df):\n",
        "        self.train_df = train_df\n",
        "        self.scaler = StandardScaler()\n",
        "        self.best_models = {}\n",
        "        self.cv_results = {}\n",
        "\n",
        "    def prepare_features(self):\n",
        "        \"\"\"Prepare features for training with imputation and overfitting prevention.\"\"\"\n",
        "        exclude_cols = ['SOH', 'battery_id', 'datetime']\n",
        "        feature_cols = [col for col in self.train_df.columns if col not in exclude_cols]\n",
        "\n",
        "        X = self.train_df[feature_cols]\n",
        "        y = self.train_df['SOH']\n",
        "\n",
        "        # Replace infinite values with NaN\n",
        "        X = X.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        # Perform iterative imputation for missing values\n",
        "        self.imputer = IterativeImputer(\n",
        "            estimator=ExtraTreesRegressor(n_estimators=10),\n",
        "            max_iter=10,\n",
        "            random_state=42\n",
        "        )\n",
        "        X = pd.DataFrame(self.imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "        # Feature engineering to prevent overfitting\n",
        "        def remove_correlated_features(X, threshold=0.95):\n",
        "            corr_matrix = X.corr().abs()\n",
        "            upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "            to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "            return X.drop(columns=to_drop)\n",
        "\n",
        "        def select_relevant_features(X, y, threshold=0.1):\n",
        "            correlations = np.abs(pd.DataFrame(X).corrwith(pd.Series(y)))\n",
        "            selected_features = correlations[correlations > threshold].index\n",
        "            return X[selected_features]\n",
        "\n",
        "        X = remove_correlated_features(X)\n",
        "        X = select_relevant_features(X, y)\n",
        "\n",
        "        self.selected_features = X.columns.tolist()\n",
        "\n",
        "        # Save features to file\n",
        "        with open('selected_features.pkl', 'wb') as f:\n",
        "            pickle.dump(self.selected_features, f)\n",
        "\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X, y, test_size=0.2, random_state=42, shuffle=False\n",
        "        )\n",
        "\n",
        "        # Scale features\n",
        "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
        "        X_test_scaled = self.scaler.transform(X_test)\n",
        "\n",
        "        # Convert back to DataFrame for easier interpretation\n",
        "        X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
        "        X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
        "\n",
        "        return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "    def tune_models(self, X_train, y_train):\n",
        "        \"\"\"Tune models using grid search for optimal hyperparameters.\"\"\"\n",
        "        param_grids = {\n",
        "            'GradientBoost': {\n",
        "                'n_estimators': [100, 150],\n",
        "                'learning_rate': [0.05, 0.1],\n",
        "                'max_depth': [3, 4]\n",
        "            },\n",
        "            'RandomForest': {\n",
        "                'n_estimators': [100, 150],\n",
        "                'max_depth': [None, 10],\n",
        "                'min_samples_split': [2, 5]\n",
        "            }\n",
        "        }\n",
        "\n",
        "        models = {\n",
        "            'GradientBoost': GradientBoostingRegressor(random_state=42),\n",
        "            'RandomForest': RandomForestRegressor(random_state=42)\n",
        "        }\n",
        "\n",
        "        # Perform grid search with cross-validation\n",
        "        for name, model in models.items():\n",
        "            print(f\"\\nTuning {name}...\")\n",
        "\n",
        "            grid_search = GridSearchCV(\n",
        "                estimator=model,\n",
        "                param_grid=param_grids[name],\n",
        "                cv=3,\n",
        "                scoring='r2',\n",
        "                n_jobs=-1,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            grid_search.fit(X_train, y_train)\n",
        "\n",
        "            self.best_models[name] = grid_search.best_estimator_\n",
        "            self.cv_results[name] = {\n",
        "                'best_params': grid_search.best_params_,\n",
        "                'best_score': grid_search.best_score_\n",
        "            }\n",
        "\n",
        "            print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "            print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "    def evaluate_models(self, X_train, X_test, y_train, y_test):\n",
        "        \"\"\"Evaluate the performance of the tuned models.\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for name, model in self.best_models.items():\n",
        "            print(f\"\\n{name} Results:\")\n",
        "\n",
        "            # Cross-validation scores\n",
        "            cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "            cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
        "\n",
        "            print(f\"Cross-validation R2 scores: {cv_scores}\")\n",
        "            print(f\"Mean CV R2: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "            # Predictions\n",
        "            y_train_pred = model.predict(X_train)\n",
        "            y_test_pred = model.predict(X_test)\n",
        "\n",
        "            # Metrics\n",
        "            train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "            test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "            train_r2 = r2_score(y_train, y_train_pred)\n",
        "            test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "            metrics = {\n",
        "                'Train MAE': train_mae,\n",
        "                'Test MAE': test_mae,\n",
        "                'Train RMSE': train_rmse,\n",
        "                'Test RMSE': test_rmse,\n",
        "                'Train R2': train_r2,\n",
        "                'Test R2': test_r2,\n",
        "                'CV R2 Mean': cv_scores.mean(),\n",
        "                'CV R2 Std': cv_scores.std(),\n",
        "            }\n",
        "\n",
        "            for metric, value in metrics.items():\n",
        "                print(f\"{metric}: {value}\")\n",
        "\n",
        "            results[name] = metrics\n",
        "\n",
        "        return results\n",
        "\n",
        "    def plot_feature_importance(self, X_columns):\n",
        "        \"\"\"Plot feature importance for the tuned models.\"\"\"\n",
        "        plt.figure(figsize=(15, 6))\n",
        "\n",
        "        for idx, (name, model) in enumerate(self.best_models.items(), 1):\n",
        "            plt.subplot(1, 2, idx)\n",
        "\n",
        "            if hasattr(model, 'feature_importances_'):\n",
        "                importance = model.feature_importances_\n",
        "                indices = np.argsort(importance)[-10:]\n",
        "                plt.barh(range(10), importance[indices])\n",
        "                plt.yticks(range(10), X_columns[indices])\n",
        "                plt.xlabel('Feature Importance')\n",
        "                plt.title(f'{name} - Top 10 Features')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "6d619_pEGq-1"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize and prepare data\n",
        "tuned_predictor = TrainDataSOHPredictor(train_df)\n",
        "X_train_scaled, X_test_scaled, y_train, y_test = tuned_predictor.prepare_features()\n",
        "\n",
        "# Perform hyperparameter tuning\n",
        "tuned_predictor.tune_models(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "6YIjhu9RAuuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9263669-94fd-4963-cad1-655b7642704d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tuning GradientBoost...\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best parameters for GradientBoost: {'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 150}\n",
            "Best cross-validation score: 0.9909\n",
            "\n",
            "Tuning RandomForest...\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
            "Best parameters for RandomForest: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 150}\n",
            "Best cross-validation score: 0.9750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate models with cross-validation\n",
        "results = tuned_predictor.evaluate_models(\n",
        "X_train_scaled, X_test_scaled, y_train, y_test)\n",
        "\n",
        "# Plot feature importance\n",
        "# tuned_predictor.plot_feature_importance(X_train.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvgbu62p7iCI",
        "outputId": "de14d49d-210d-4de0-d087-c63901279c2d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GradientBoost Results:\n",
            "Cross-validation R2 scores: [0.9999113  0.99980359 0.99989354 0.99985835 0.99797525]\n",
            "Mean CV R2: 0.9995 (+/- 0.0015)\n",
            "Train MAE: 0.047332572052374684\n",
            "Test MAE: 0.5090179758962423\n",
            "Train RMSE: 0.06238808687978226\n",
            "Test RMSE: 0.8952669099951583\n",
            "Train R2: 0.9999922457510623\n",
            "Test R2: 0.9958539229296276\n",
            "CV R2 Mean: 0.9994884048938685\n",
            "CV R2 Std: 0.0007574695448797356\n",
            "\n",
            "RandomForest Results:\n",
            "Cross-validation R2 scores: [0.99983175 0.99978314 0.99965398 0.99993673 0.99760883]\n",
            "Mean CV R2: 0.9994 (+/- 0.0018)\n",
            "Train MAE: 0.024550798578398723\n",
            "Test MAE: 2.169697640919913\n",
            "Train RMSE: 0.21185086670899433\n",
            "Test RMSE: 2.9705117308648887\n",
            "Train R2: 0.9999105877769439\n",
            "Test R2: 0.9543548279094914\n",
            "CV R2 Mean: 0.9993628877311925\n",
            "CV R2 Std: 0.0008817266193148055\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_correlated_features(X, threshold=0.95):\n",
        "    corr_matrix = X.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "\n",
        "    # Add logging to understand which features are being dropped\n",
        "    if to_drop:\n",
        "        print(f\"Dropping correlated features: {to_drop}\")\n",
        "\n",
        "    return X.drop(columns=to_drop)\n",
        "\n",
        "def select_relevant_features(X, y, threshold=0.1):\n",
        "    # Use mutual information for feature selection\n",
        "    from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "    # Calculate mutual information scores\n",
        "    mi_scores = mutual_info_regression(X, y)\n",
        "\n",
        "    # Create a series of scores\n",
        "    mi_series = pd.Series(mi_scores, index=X.columns)\n",
        "\n",
        "    # Select top features based on mutual information\n",
        "    selected_features = mi_series[mi_series > threshold]\n",
        "\n",
        "    print(\"Selected features based on mutual information:\")\n",
        "    print(selected_features)\n",
        "\n",
        "    return X[selected_features.index]"
      ],
      "metadata": {
        "id": "GCVmr3YyaKmx"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "\n",
        "def time_series_cross_validation(model, X, y):\n",
        "    \"\"\"Perform time series cross-validation\"\"\"\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "    cv_scores = []\n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        score = r2_score(y_test, model.predict(X_test))\n",
        "        cv_scores.append(score)\n",
        "\n",
        "    return cv_scores"
      ],
      "metadata": {
        "id": "MGyYljoyaMY6"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def enhanced_model_evaluation(self, X_train, X_test, y_train, y_test):\n",
        "    results = {}\n",
        "\n",
        "    for name, model in self.best_models.items():\n",
        "        # Standard cross-validation\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
        "\n",
        "        # Time series cross-validation\n",
        "        ts_cv_scores = time_series_cross_validation(model, X_train, y_train)\n",
        "\n",
        "        # Predictions\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        # Metrics\n",
        "        metrics = {\n",
        "            'Standard CV R2 Mean': cv_scores.mean(),\n",
        "            'Standard CV R2 Std': cv_scores.std(),\n",
        "            'Time Series CV R2 Mean': np.mean(ts_cv_scores),\n",
        "            'Time Series CV R2 Std': np.std(ts_cv_scores),\n",
        "            'Train MAE': mean_absolute_error(y_train, y_train_pred),\n",
        "            'Test MAE': mean_absolute_error(y_test, y_test_pred),\n",
        "            'Train R2': r2_score(y_train, y_train_pred),\n",
        "            'Test R2': r2_score(y_test, y_test_pred)\n",
        "        }\n",
        "\n",
        "        results[name] = metrics\n",
        "\n",
        "        # Residual analysis\n",
        "        self.plot_residuals(y_train, y_train_pred, name + ' Train')\n",
        "        self.plot_residuals(y_test, y_test_pred, name + ' Test')\n",
        "\n",
        "    return results\n",
        "\n",
        "def plot_residuals(self, y_true, y_pred, title):\n",
        "    residuals = y_true - y_pred\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(y_pred, residuals)\n",
        "    plt.title(f'Residual Plot - {title}')\n",
        "    plt.xlabel('Predicted Values')\n",
        "    plt.ylabel('Residuals')\n",
        "    plt.axhline(y=0, color='r', linestyle='--')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.histplot(residuals, kde=True)\n",
        "    plt.title(f'Residual Distribution - {title}')\n",
        "    plt.xlabel('Residuals')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "50EoT9DbaPzg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_with_uncertainty(self, X, model_name='GradientBoost'):\n",
        "    \"\"\"\n",
        "    Estimate prediction uncertainty using ensemble methods\n",
        "    \"\"\"\n",
        "    model = self.best_models[model_name]\n",
        "\n",
        "    if hasattr(model, 'estimators_'):\n",
        "        # For ensemble methods like Random Forest\n",
        "        predictions = np.array([tree.predict(X) for tree in model.estimators_])\n",
        "        mean_prediction = predictions.mean(axis=0)\n",
        "        prediction_std = predictions.std(axis=0)\n",
        "\n",
        "        return mean_prediction, prediction_std\n",
        "    else:\n",
        "        return model.predict(X), None"
      ],
      "metadata": {
        "id": "rSmaLqTbaTfV"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save the iterative imputer scaler\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Assuming 'imputer' and 'scaler' are your fitted objects\n",
        "# Replace with your actual variable names\n",
        "# Example: imputer = IterativeImputer(...)\n",
        "# Example: scaler = StandardScaler(...)\n",
        "\n",
        "# Save the imputer\n",
        "joblib.dump(tuned_predictor.imputer, 'imputer.pkl')\n",
        "\n",
        "# Save the scaler\n",
        "joblib.dump(tuned_predictor.scaler, 'scaler.pkl')"
      ],
      "metadata": {
        "id": "ifZaDR6YAsMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d033097-ec03-451a-ed44-98f20662c5b9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['scaler.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save the Gradient Boosting model.\n",
        "\n",
        "import joblib\n",
        "\n",
        "# Assuming 'tuned_predictor' is your initialized and trained BatterySOHPredictorTuned object\n",
        "\n",
        "# Save the best Gradient Boosting model\n",
        "#joblib.dump(tuned_predictor.best_models['GradientBoost'], '/content/drive/My Drive/gradient_boosting_model_v5_01.pkl')\n",
        "joblib.dump(tuned_predictor.best_models['GradientBoost'], 'gradient_boosting_model_v5_01.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcwCrjsIX48R",
        "outputId": "366d0e77-9d44-4dad-d61c-f3c4aa809143"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gradient_boosting_model_v5_01.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "lU78u9zH7VA2",
        "outputId": "f45d835a-ad95-4b7c-9f9b-c01c0a499fa7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  battery_id  cycle_number  ambient_temperature  capacity            datetime  \\\n",
              "0      B0029             1                   43  1.697507 2009-04-07 16:31:01   \n",
              "1      B0029             2                   43  1.844701 2009-04-07 19:44:26   \n",
              "2      B0029             3                   43  1.825438 2009-04-07 22:58:18   \n",
              "3      B0029             4                   43  1.815750 2009-04-08 02:11:30   \n",
              "4      B0029             5                   43  1.813299 2009-04-08 05:23:26   \n",
              "\n",
              "   voltage_min  voltage_max  voltage_mean  current_mean  temperature_max  ...  \\\n",
              "0     1.999936     4.122759      3.365186     -3.975396        58.726269  ...   \n",
              "1     1.852059     4.201346      3.390593     -3.934249        59.767964  ...   \n",
              "2     1.885726     4.200751      3.394458     -3.933295        59.844347  ...   \n",
              "3     1.853478     4.201219      3.394696     -3.932113        59.919947  ...   \n",
              "4     1.913444     4.201517      3.398579     -3.931581        59.894754  ...   \n",
              "\n",
              "   capacity_mean_5  capacity_std_5  voltage_mean_5  temperature_mean_5  \\\n",
              "0              NaN             NaN             NaN                 NaN   \n",
              "1         1.697507             NaN        3.365186           51.631546   \n",
              "2         1.771104        0.104082        3.377889           52.240494   \n",
              "3         1.789215        0.080003        3.383412           52.462285   \n",
              "4         1.795849        0.066656        3.386233           52.572810   \n",
              "\n",
              "   capacity_mean_10  capacity_std_10  voltage_mean_10  temperature_mean_10  \\\n",
              "0               NaN              NaN              NaN                  NaN   \n",
              "1          1.697507              NaN         3.365186            51.631546   \n",
              "2          1.771104         0.104082         3.377889            52.240494   \n",
              "3          1.789215         0.080003         3.383412            52.462285   \n",
              "4          1.795849         0.066656         3.386233            52.572810   \n",
              "\n",
              "   capacity_rate  capacity_pct_initial  \n",
              "0            NaN            100.000000  \n",
              "1       0.086712            108.671178  \n",
              "2      -0.010443            107.536364  \n",
              "3      -0.005307            106.965690  \n",
              "4      -0.001350            106.821296  \n",
              "\n",
              "[5 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6073cfd-753b-4637-be66-8ef49c51b6d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>battery_id</th>\n",
              "      <th>cycle_number</th>\n",
              "      <th>ambient_temperature</th>\n",
              "      <th>capacity</th>\n",
              "      <th>datetime</th>\n",
              "      <th>voltage_min</th>\n",
              "      <th>voltage_max</th>\n",
              "      <th>voltage_mean</th>\n",
              "      <th>current_mean</th>\n",
              "      <th>temperature_max</th>\n",
              "      <th>...</th>\n",
              "      <th>capacity_mean_5</th>\n",
              "      <th>capacity_std_5</th>\n",
              "      <th>voltage_mean_5</th>\n",
              "      <th>temperature_mean_5</th>\n",
              "      <th>capacity_mean_10</th>\n",
              "      <th>capacity_std_10</th>\n",
              "      <th>voltage_mean_10</th>\n",
              "      <th>temperature_mean_10</th>\n",
              "      <th>capacity_rate</th>\n",
              "      <th>capacity_pct_initial</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B0029</td>\n",
              "      <td>1</td>\n",
              "      <td>43</td>\n",
              "      <td>1.697507</td>\n",
              "      <td>2009-04-07 16:31:01</td>\n",
              "      <td>1.999936</td>\n",
              "      <td>4.122759</td>\n",
              "      <td>3.365186</td>\n",
              "      <td>-3.975396</td>\n",
              "      <td>58.726269</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>100.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B0029</td>\n",
              "      <td>2</td>\n",
              "      <td>43</td>\n",
              "      <td>1.844701</td>\n",
              "      <td>2009-04-07 19:44:26</td>\n",
              "      <td>1.852059</td>\n",
              "      <td>4.201346</td>\n",
              "      <td>3.390593</td>\n",
              "      <td>-3.934249</td>\n",
              "      <td>59.767964</td>\n",
              "      <td>...</td>\n",
              "      <td>1.697507</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.365186</td>\n",
              "      <td>51.631546</td>\n",
              "      <td>1.697507</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.365186</td>\n",
              "      <td>51.631546</td>\n",
              "      <td>0.086712</td>\n",
              "      <td>108.671178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B0029</td>\n",
              "      <td>3</td>\n",
              "      <td>43</td>\n",
              "      <td>1.825438</td>\n",
              "      <td>2009-04-07 22:58:18</td>\n",
              "      <td>1.885726</td>\n",
              "      <td>4.200751</td>\n",
              "      <td>3.394458</td>\n",
              "      <td>-3.933295</td>\n",
              "      <td>59.844347</td>\n",
              "      <td>...</td>\n",
              "      <td>1.771104</td>\n",
              "      <td>0.104082</td>\n",
              "      <td>3.377889</td>\n",
              "      <td>52.240494</td>\n",
              "      <td>1.771104</td>\n",
              "      <td>0.104082</td>\n",
              "      <td>3.377889</td>\n",
              "      <td>52.240494</td>\n",
              "      <td>-0.010443</td>\n",
              "      <td>107.536364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B0029</td>\n",
              "      <td>4</td>\n",
              "      <td>43</td>\n",
              "      <td>1.815750</td>\n",
              "      <td>2009-04-08 02:11:30</td>\n",
              "      <td>1.853478</td>\n",
              "      <td>4.201219</td>\n",
              "      <td>3.394696</td>\n",
              "      <td>-3.932113</td>\n",
              "      <td>59.919947</td>\n",
              "      <td>...</td>\n",
              "      <td>1.789215</td>\n",
              "      <td>0.080003</td>\n",
              "      <td>3.383412</td>\n",
              "      <td>52.462285</td>\n",
              "      <td>1.789215</td>\n",
              "      <td>0.080003</td>\n",
              "      <td>3.383412</td>\n",
              "      <td>52.462285</td>\n",
              "      <td>-0.005307</td>\n",
              "      <td>106.965690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B0029</td>\n",
              "      <td>5</td>\n",
              "      <td>43</td>\n",
              "      <td>1.813299</td>\n",
              "      <td>2009-04-08 05:23:26</td>\n",
              "      <td>1.913444</td>\n",
              "      <td>4.201517</td>\n",
              "      <td>3.398579</td>\n",
              "      <td>-3.931581</td>\n",
              "      <td>59.894754</td>\n",
              "      <td>...</td>\n",
              "      <td>1.795849</td>\n",
              "      <td>0.066656</td>\n",
              "      <td>3.386233</td>\n",
              "      <td>52.572810</td>\n",
              "      <td>1.795849</td>\n",
              "      <td>0.066656</td>\n",
              "      <td>3.386233</td>\n",
              "      <td>52.572810</td>\n",
              "      <td>-0.001350</td>\n",
              "      <td>106.821296</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6073cfd-753b-4637-be66-8ef49c51b6d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6073cfd-753b-4637-be66-8ef49c51b6d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6073cfd-753b-4637-be66-8ef49c51b6d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15163e24-4dc0-4195-b590-fb1f1d0702eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15163e24-4dc0-4195-b590-fb1f1d0702eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15163e24-4dc0-4195-b590-fb1f1d0702eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val_df"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_df.columns == train_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWhBkCOiAgTj",
        "outputId": "763f5038-3d62-430e-c136-c023e18ebdc7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True,  True,  True,  True,  True,  True,  True])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# working ValDataPreparer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import pickle\n",
        "\n",
        "class ValDataSOHPredictor:\n",
        "    def __init__(self, val_df, scaler_path='scaler.pkl', imputer_path='imputer.pkl', features_path='selected_features.pkl'):\n",
        "        \"\"\"\n",
        "        Initialize the validator with validation dataset and paths to saved preprocessors\n",
        "\n",
        "        Args:\n",
        "            val_df: Validation dataframe\n",
        "            scaler_path: Path to saved StandardScaler\n",
        "            imputer_path: Path to saved IterativeImputer\n",
        "        \"\"\"\n",
        "        self.val_df = val_df\n",
        "\n",
        "        # Load pre-fitted scaler and imputer\n",
        "        #with open(scaler_path, 'rb') as f:\n",
        "        #    self.scaler = pickle.load(f)\n",
        "        #with open(imputer_path, 'rb') as f:\n",
        "        #    self.imputer = pickle.load(f)\n",
        "\n",
        "        self.scaler = joblib.load(scaler_path)\n",
        "        self.imputer = joblib.load(imputer_path)\n",
        "        self.selected_features = joblib.load('selected_features.pkl')\n",
        "\n",
        "    def prepare_features(self):\n",
        "\n",
        "        self.val_df = self.val_df.dropna()\n",
        "        \"\"\"\n",
        "        Prepare features for validation using pre-fitted imputer and scaler\n",
        "        \"\"\"\n",
        "        exclude_cols = ['SOH', 'battery_id', 'datetime']\n",
        "        feature_cols = [col for col in self.val_df.columns if col not in exclude_cols]\n",
        "\n",
        "        X = self.val_df[feature_cols]\n",
        "        y = self.val_df['SOH']\n",
        "\n",
        "        # Replace infinite values with NaN\n",
        "        X = X.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        # Use pre-fitted imputer\n",
        "        X = pd.DataFrame(\n",
        "            self.imputer.transform(X),\n",
        "            columns=feature_cols\n",
        "        )\n",
        "\n",
        "        X = X[self.selected_features]\n",
        "\n",
        "        # Feature selection (using the same correlation thresholds as training)\n",
        "        #def remove_correlated_features(X, threshold=0.95):\n",
        "        #    corr_matrix = X.corr().abs()\n",
        "        #    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "        #    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "        #    return X.drop(columns=to_drop)\n",
        "\n",
        "        #def select_relevant_features(X, y, threshold=0.1):\n",
        "        #    correlations = np.abs(pd.DataFrame(X).corrwith(pd.Series(y)))\n",
        "        #    selected_features = correlations[correlations > threshold].index\n",
        "        #    return X[selected_features]\n",
        "\n",
        "        #X = remove_correlated_features(X)\n",
        "        #X = select_relevant_features(X, y)\n",
        "\n",
        "        # Use pre-fitted scaler\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        X_scaled = pd.DataFrame(X_scaled, columns=self.selected_features)\n",
        "\n",
        "        return X_scaled, y\n",
        "\n",
        "    def evaluate_model(self, model, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Evaluate a trained model on validation data\n",
        "\n",
        "        Args:\n",
        "            model: Trained model (GradientBoostingRegressor or RandomForestRegressor)\n",
        "            X_val: Prepared validation features\n",
        "            y_val: Validation target values\n",
        "        \"\"\"\n",
        "        # Make predictions\n",
        "        y_val_pred = model.predict(X_val)\n",
        "\n",
        "        # Calculate metrics\n",
        "        val_mae = mean_absolute_error(y_val, y_val_pred)\n",
        "        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "        val_r2 = r2_score(y_val, y_val_pred)\n",
        "\n",
        "        metrics = {\n",
        "            'Validation MAE': val_mae,\n",
        "            'Validation RMSE': val_rmse,\n",
        "            'Validation R2': val_r2\n",
        "        }\n",
        "\n",
        "        # Print metrics\n",
        "        print(\"\\nValidation Metrics:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "        return metrics, y_val_pred\n",
        "\n",
        "    def plot_predictions(self, y_val, y_val_pred, model_name):\n",
        "        \"\"\"\n",
        "        Plot actual vs predicted values and residuals\n",
        "\n",
        "        Args:\n",
        "            y_val: True validation values\n",
        "            y_val_pred: Predicted validation values\n",
        "            model_name: Name of the model used\n",
        "        \"\"\"\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "        # Actual vs Predicted plot\n",
        "        ax1.scatter(y_val, y_val_pred, alpha=0.5)\n",
        "        ax1.plot([y_val.min(), y_val.max()], [y_val.min(), y_val.max()], 'r--', lw=2)\n",
        "        ax1.set_xlabel('Actual SOH')\n",
        "        ax1.set_ylabel('Predicted SOH')\n",
        "        ax1.set_title(f'{model_name} - Actual vs Predicted SOH')\n",
        "\n",
        "        # Residuals plot\n",
        "        residuals = y_val_pred - y_val\n",
        "        ax2.scatter(y_val_pred, residuals, alpha=0.5)\n",
        "        ax2.axhline(y=0, color='r', linestyle='--')\n",
        "        ax2.set_xlabel('Predicted SOH')\n",
        "        ax2.set_ylabel('Residuals')\n",
        "        ax2.set_title('Residuals Plot')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    def plot_battery_predictions(self, model, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Plot predictions for each battery separately\n",
        "\n",
        "        Args:\n",
        "            model: Trained model\n",
        "            X_val: Prepared validation features\n",
        "            y_val: Validation target values\n",
        "        \"\"\"\n",
        "        y_val_pred = model.predict(X_val)\n",
        "\n",
        "        plt.figure(figsize=(15, 8))\n",
        "\n",
        "        for battery in self.val_df['battery_id'].unique():\n",
        "            battery_mask = self.val_df['battery_id'] == battery\n",
        "            cycles = self.val_df[battery_mask]['cycle_number']\n",
        "\n",
        "            actual = y_val[self.val_df['battery_id'] == battery]\n",
        "            predicted = y_val_pred[self.val_df['battery_id'] == battery]\n",
        "\n",
        "            plt.plot(cycles, actual, 'o-', label=f'{battery} (Actual)', alpha=0.5)\n",
        "            plt.plot(cycles, predicted, 's--', label=f'{battery} (Predicted)', alpha=0.5)\n",
        "\n",
        "        plt.xlabel('Cycle Number')\n",
        "        plt.ylabel('SOH')\n",
        "        plt.title('SOH Degradation: Actual vs Predicted by Battery')\n",
        "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "qOBsEt0E83Fv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = ValDataSOHPredictor(val_df)\n",
        "X_train, X_test, y_train, y_test = predictor.prepare_features()\n",
        "results = predictor.train_and_evaluate_models(X_train, X_test, y_train, y_test)\n",
        "predictor.visualize_best_model(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "sNOhxBMyfgez",
        "outputId": "a6d5e408-0bae-4063-93b2-afc9dc1e1176"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "not enough values to unpack (expected 4, got 2)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-ee1551431f34>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mValDataSOHPredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_best_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ValDataSOHPredictor:\n",
        "    def __init__(self, val_df, scaler_path='scaler.pkl', imputer_path='imputer.pkl', features_path='selected_features.pkl'):\n",
        "        \"\"\"\n",
        "        Initialize the validator with validation dataset and paths to saved preprocessors\n",
        "\n",
        "        Args:\n",
        "            val_df: Validation dataframe\n",
        "            scaler_path: Path to saved StandardScaler\n",
        "            imputer_path: Path to saved IterativeImputer\n",
        "        \"\"\"\n",
        "        self.val_df = val_df\n",
        "\n",
        "        # Load pre-fitted scaler, imputer, and selected features\n",
        "        self.scaler = joblib.load(scaler_path)\n",
        "        self.imputer = joblib.load(imputer_path)\n",
        "        self.selected_features = joblib.load(features_path)\n",
        "\n",
        "    def prepare_features(self):\n",
        "        \"\"\"\n",
        "        Prepare features for validation using pre-fitted imputer and scaler, with added noise.\n",
        "        \"\"\"\n",
        "\n",
        "        self.val_df = self.val_df.dropna()\n",
        "\n",
        "        exclude_cols = ['SOH', 'battery_id', 'datetime']\n",
        "        feature_cols = [col for col in self.val_df.columns if col not in exclude_cols]\n",
        "\n",
        "        X = self.val_df[feature_cols]\n",
        "        y = self.val_df['SOH']\n",
        "\n",
        "        # Replace infinite values with NaN\n",
        "        X = X.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        # Use pre-fitted imputer\n",
        "        X = pd.DataFrame(\n",
        "            self.imputer.transform(X),\n",
        "            columns=feature_cols\n",
        "        )\n",
        "\n",
        "        # Select features\n",
        "        X = X[self.selected_features]\n",
        "\n",
        "        # Use pre-fitted scaler\n",
        "        X_scaled = self.scaler.transform(X)\n",
        "        X_scaled = pd.DataFrame(X_scaled, columns=self.selected_features)\n",
        "\n",
        "        # Add noise to scaled features\n",
        "        '''def add_noise(X, noise_range=(0.2, 0.3)):\n",
        "            \"\"\"\n",
        "            Add random noise to features within a specified percentage range.\n",
        "\n",
        "            Args:\n",
        "                X: Feature dataframe\n",
        "                noise_range: Tuple indicating the min and max percentage noise to add\n",
        "\n",
        "            Returns:\n",
        "                Noisy feature dataframe\n",
        "            \"\"\"\n",
        "            noise = np.random.uniform(\n",
        "                low=1 - noise_range[1],\n",
        "                high=1 + noise_range[1],\n",
        "                size=X.shape\n",
        "            )\n",
        "            return X * noise\n",
        "\n",
        "        X_noisy = add_noise(X_scaled)\n",
        "\n",
        "        return X_noisy, y'''\n",
        "        return X_scaled, y\n",
        "\n",
        "    def evaluate_model(self, model, X_val, y_val):\n",
        "        \"\"\"\n",
        "        Evaluate a trained model on validation data\n",
        "\n",
        "        Args:\n",
        "            model: Trained model (GradientBoostingRegressor or RandomForestRegressor)\n",
        "            X_val: Prepared validation features\n",
        "            y_val: Validation target values\n",
        "        \"\"\"\n",
        "        # Make predictions\n",
        "        y_val_pred = model.predict(X_val)\n",
        "\n",
        "        # Calculate metrics\n",
        "        val_mae = mean_absolute_error(y_val, y_val_pred)\n",
        "        val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
        "        val_r2 = r2_score(y_val, y_val_pred)\n",
        "\n",
        "        metrics = {\n",
        "            'Validation MAE': val_mae,\n",
        "            'Validation RMSE': val_rmse,\n",
        "            'Validation R2': val_r2\n",
        "        }\n",
        "\n",
        "        # Print metrics\n",
        "        print(\"\\nValidation Metrics:\")\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric}: {value:.4f}\")\n",
        "\n",
        "        return metrics, y_val_pred\n"
      ],
      "metadata": {
        "id": "TTxrrqtyGtja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Assuming val_df and trained_model are available\n",
        "    val_predictor = ValDataSOHPredictor(val_df)\n",
        "\n",
        "    # Prepare validation features\n",
        "    X_val, y_val = val_predictor.prepare_features()\n",
        "\n",
        "    # Prepare model\n",
        "    trained_model = joblib.load('gradient_boosting_model_v5_01.pkl')\n",
        "\n",
        "    # Evaluate model\n",
        "    metrics, predictions = val_predictor.evaluate_model(trained_model, X_val, y_val)\n",
        "\n",
        "    # Plot results\n",
        "   # val_predictor.plot_predictions(y_val, predictions, \"GradientBoost\")\n",
        "   # val_predictor.plot_battery_predictions(trained_model, X_val, y_val)"
      ],
      "metadata": {
        "id": "qsQiQcI--uex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: convert X_val to dataframe and display head()\n",
        "\n",
        "X_val_df = pd.DataFrame(X_val)\n",
        "X_val_df.head()\n",
        "\n",
        "X_val_df.describe().T"
      ],
      "metadata": {
        "id": "sRsJqnsyBrbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your validation dataframe\n",
        "val_predictor = ValDataSOHPredictor(val_df)\n",
        "\n",
        "# Prepare features\n",
        "X_val, y_val = val_predictor.prepare_features()\n",
        "\n",
        "\n",
        "\n",
        "# For each trained model you want to evaluate:\n",
        "metrics, predictions = val_predictor.evaluate_model(trained_model, X_val, y_val)\n",
        "\n",
        "# Generate visualizations\n",
        "# val_predictor.plot_predictions(y_val, predictions, \"Model Name\")\n",
        "val_predictor.plot_battery_predictions(trained_model, X_val, y_val)"
      ],
      "metadata": {
        "id": "to1q1q_a84aI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Misc"
      ],
      "metadata": {
        "id": "X3YzQfpt7VSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the feature list after preprocessing\n",
        "feature_list = list(X_train_scaled.columns)\n",
        "joblib.dump(feature_list, 'feature_list.pkl')\n"
      ],
      "metadata": {
        "id": "f9W2feSHlVMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: save out.df to a csv\n",
        "\n",
        "tuned_predictor.out_df.to_csv('out.csv', index=False)"
      ],
      "metadata": {
        "id": "qba5H4VQMGTS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuned_predictor.out_df.info()"
      ],
      "metadata": {
        "id": "zFchLP6vMSYF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "['temperature_mean', 'voltage_mean', 'current_mean', 'capacity']"
      ],
      "metadata": {
        "id": "pFKgAS1psDz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze | grep scikit-learn\n",
        "!pip freeze | grep joblib"
      ],
      "metadata": {
        "id": "A9WxvVs_3gml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check versions of all these libraries:\n",
        "# flask==2.0.1\n",
        "# werkzeug==2.0.3\n",
        "# pandas==1.3.3\n",
        "# scikit-learn==1.5.2\n",
        "# numpy==1.21.2\n",
        "# gunicorn==20.1.0\n",
        "# joblib==1.5.2\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def get_package_version(package_name):\n",
        "    try:\n",
        "        result = subprocess.run(['pip', 'show', package_name], capture_output=True, text=True, check=True)\n",
        "        for line in result.stdout.splitlines():\n",
        "            if line.startswith('Version:'):\n",
        "                return line.split(':')[1].strip()\n",
        "        return None  # Version not found\n",
        "    except subprocess.CalledProcessError:\n",
        "        return None  # Package not found\n",
        "\n",
        "packages = {\n",
        "    'flask': '2.0.1',\n",
        "    'werkzeug': '2.0.3',\n",
        "    'pandas': '1.3.3',\n",
        "    'scikit-learn': '1.5.2',\n",
        "    'numpy': '1.21.2',\n",
        "    'gunicorn': '20.1.0',\n",
        "    'joblib': '1.5.2'\n",
        "}\n",
        "\n",
        "for package, expected_version in packages.items():\n",
        "    version = get_package_version(package)\n",
        "    if version:\n",
        "        print(f'{package}: Installed version - {version}, Expected version - {expected_version}')\n",
        "    else:\n",
        "        print(f'{package}: Not installed')"
      ],
      "metadata": {
        "id": "2OC9C7Y3DWWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "4Zx_czgs3mJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: check python version\n",
        "\n",
        "import sys\n",
        "sys.version"
      ],
      "metadata": {
        "id": "dNAZ-qch59Pi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "# Load the saved Gradient Boosting model\n",
        "loaded_model = joblib.load('/content/drive/My Drive/gradient_boosting_model_v3.pkl')\n",
        "\n",
        "# Assuming 'out_df' is your DataFrame with the records for inference\n",
        "# Replace 'out.csv' with the actual path to your out_df file\n",
        "out_df = pd.read_csv('out.csv')\n",
        "\n",
        "# Get the feature names the model was trained on\n",
        "training_feature_names = tuned_predictor.scaler.feature_names_in_\n",
        "\n",
        "# Ensure X_inference has the same columns in the same order as training data\n",
        "X_inference = out_df[training_feature_names]\n",
        "\n",
        "# Scale features using the same scaler used during training\n",
        "X_inference_scaled = tuned_predictor.scaler.transform(X_inference)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = loaded_model.predict(X_inference_scaled)\n",
        "\n",
        "# Display actual and predicted values\n",
        "print(\"Actual vs Predicted Values:\")\n",
        "for i in range(len(out_df)):\n",
        "  print(f\"Record {i+1}: Actual SOH = {out_df['SOH'].iloc[i]}, Predicted SOH = {y_pred[i]}\")"
      ],
      "metadata": {
        "id": "GQng0t49Mb4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Load model from Google Drive, its named as 'gradient_boosting_model_v3.pkl'. Then, run inference on it using out_df, and print the evaluation metrics.\n",
        "\n",
        "# Load the saved Gradient Boosting model\n",
        "loaded_model = joblib.load('/content/gradient_boosting_model_v5_01.pkl')\n",
        "\n",
        "# Assuming 'out_df' is your DataFrame with the records for inference\n",
        "# Replace 'out.csv' with the actual path to your out_df file\n",
        "out_df = pd.read_csv('/content/cleaned_dataset/metadata.csv')\n",
        "\n",
        "# Get the feature names the model was trained on\n",
        "feature_list = joblib.load('/content/selected_features.pkl')\n",
        "\n",
        "\n",
        "# Ensure X_inference has the same columns in the same order as training data\n",
        "X_inference = out_df[feature_list]\n",
        "\n",
        "# Load the scaler\n",
        "scaler = joblib.load('scaler.pkl')\n",
        "\n",
        "# Scale features using the same scaler used during training\n",
        "X_inference_scaled = scaler.transform(X_inference)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = loaded_model.predict(X_inference_scaled)\n",
        "\n",
        "# Evaluate the model on the inference data\n",
        "mae = mean_absolute_error(out_df['SOH'], y_pred)\n",
        "mse = mean_squared_error(out_df['SOH'], y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(out_df['SOH'], y_pred)\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
        "print(f\"Mean Squared Error (MSE): {mse}\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n",
        "print(f\"R-squared (R2): {r2}\")"
      ],
      "metadata": {
        "id": "LP5pxeggyr9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previous:\n",
        "\n",
        "Mean Absolute Error (MAE): 0.1317185813160859\n",
        "Mean Squared Error (MSE): 0.17074409977468324\n",
        "Root Mean Squared Error (RMSE): 0.4132119308232559\n",
        "R-squared (R2): 0.9996839225247577"
      ],
      "metadata": {
        "id": "DLR6tA8LzxTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Find out what values to give to the model, if we want to run it for inference.\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the saved model\n",
        "loaded_gb_model = joblib.load('/content/drive/My Drive/gradient_boosting_model_test.pkl')\n",
        "\n",
        "# Sample input features (replace with your actual data)\n",
        "# The input features MUST be in the same order and number as they were during training.\n",
        "# If you have different features in the test data than in the training data,\n",
        "# you'll need to retrain your model.\n",
        "\n",
        "# Example (replace with your actual data)\n",
        "sample_input = {\n",
        "    'feature1': [1.0],\n",
        "    'feature2': [2.0],\n",
        "    # ... add other features\n",
        "}\n",
        "\n",
        "# Create a pandas DataFrame from the sample input\n",
        "sample_df = pd.DataFrame(sample_input)\n",
        "\n",
        "# Initialize a StandardScaler object - Use the same scaler used for training\n",
        "scaler = StandardScaler()\n",
        "\n",
        "\n",
        "# Fit the scaler ONLY on the training data and then transform the sample input using the fitted scaler\n",
        "X_train, _, _, _ = tuned_predictor.prepare_features()\n",
        "scaler.fit(X_train) # fit scaler on training features\n",
        "\n",
        "# Now, transform your sample input using the fitted scaler\n",
        "scaled_sample_input = scaler.transform(sample_df)\n",
        "\n",
        "# Make predictions\n",
        "prediction = loaded_gb_model.predict(scaled_sample_input)\n",
        "print(f\"Prediction: {prediction}\")\n"
      ],
      "metadata": {
        "id": "vHcDWcDFBuRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Meta Ensemble\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    GridSearchCV,\n",
        "    RandomizedSearchCV,\n",
        "    KFold,\n",
        "    cross_val_score\n",
        ")\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.impute import KNNImputer, SimpleImputer, IterativeImputer\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.ensemble import ExtraTreesRegressor\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class MetaEnsemble(BaseEstimator, RegressorMixin):\n",
        "    \"\"\"Meta-ensemble that combines predictions from multiple models\"\"\"\n",
        "    def __init__(self, models, weights=None):\n",
        "        self.models = models\n",
        "        self.weights = weights if weights is not None else np.ones(len(models)) / len(models)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"Fit all models in the ensemble\"\"\"\n",
        "        for model in self.models:\n",
        "            model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make weighted predictions\"\"\"\n",
        "        predictions = np.column_stack([\n",
        "            model.predict(X) for model in self.models\n",
        "        ])\n",
        "        return np.average(predictions, weights=self.weights, axis=1)\n",
        "\n",
        "    def set_weights(self, weights):\n",
        "        \"\"\"Update ensemble weights\"\"\"\n",
        "        self.weights = weights\n",
        "\n",
        "class BatterySOHPredictorTuned:\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "        self.scaler = StandardScaler()\n",
        "        self.best_models = {}\n",
        "        self.cv_results = {}\n",
        "        self.meta_ensemble = None\n",
        "        self.best_weights = None\n",
        "\n",
        "    # [Previous prepare_features method remains the same]\n",
        "\n",
        "    def prepare_features(self):\n",
        "        \"\"\"Prepare features with advanced imputation methods and overfitting prevention\"\"\"\n",
        "        exclude_cols = ['SOH', 'battery_id', 'datetime']\n",
        "        feature_cols = [col for col in self.df.columns if col not in exclude_cols]\n",
        "\n",
        "        X = self.df[feature_cols]\n",
        "        y = self.df['SOH']\n",
        "\n",
        "        # Handle infinite values first\n",
        "        X = X.replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "        # ---------- Basic Imputation Methods (commented) ----------\n",
        "        #Mean imputation\n",
        "        #X = X.fillna(X.mean())\n",
        "\n",
        "        # Median imputation\n",
        "        # X = X.fillna(X.median())\n",
        "\n",
        "        # ---------- Advanced Imputation Methods ----------\n",
        "\n",
        "        # 1. KNN Imputation\n",
        "        # Good for finding patterns in data, considers feature relationships\n",
        "        # imputer = KNNImputer(n_neighbors=5, weights='uniform')\n",
        "        # X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "         #2. Iterative Imputation (MICE - Multivariate Imputation by Chained Equations)\n",
        "         #Uses all features to predict missing values through multiple rounds\n",
        "        imputer = IterativeImputer(\n",
        "             estimator=ExtraTreesRegressor(n_estimators=100),\n",
        "             max_iter=10,\n",
        "             random_state=42\n",
        "        )\n",
        "        X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "        # 3. ANOVA-based imputation for categorical variables\n",
        "        # def anova_impute(df, target_col):\n",
        "        #     grouped_means = df.groupby(target_col).mean()\n",
        "        #     return df.fillna(grouped_means)\n",
        "        #\n",
        "        # categorical_cols = X.select_dtypes(include=['category', 'object']).columns\n",
        "        # for col in categorical_cols:\n",
        "        #     X[col] = anova_impute(X, col)\n",
        "\n",
        "        # ---------- Feature Engineering for Overfitting Prevention ----------\n",
        "\n",
        "        # 1. Add noise to training data (helps prevent overfitting)\n",
        "        def add_noise(X, noise_level=0.01):\n",
        "            noise = np.random.normal(0, noise_level, X.shape)\n",
        "            return X + noise\n",
        "\n",
        "        # 2. Feature selection based on correlation with target\n",
        "        def select_relevant_features(X, y, threshold=0.1):\n",
        "            correlations = np.abs(pd.DataFrame(X).corrwith(pd.Series(y)))\n",
        "            selected_features = correlations[correlations > threshold].index\n",
        "            return X[selected_features]\n",
        "\n",
        "        # 3. Remove highly correlated features\n",
        "        def remove_correlated_features(X, threshold=0.95):\n",
        "            corr_matrix = X.corr().abs()\n",
        "            upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "            to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "            return X.drop(columns=to_drop)\n",
        "\n",
        "        # Apply overfitting prevention techniques\n",
        "        X = remove_correlated_features(X)\n",
        "        X = select_relevant_features(X, y)\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.fit_transform(X)\n",
        "        X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "        # Optional: Add noise to training data\n",
        "        # X_scaled = add_noise(X_scaled)\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_scaled, y, test_size=0.2, random_state=42, shuffle=False\n",
        "        )\n",
        "\n",
        "        return X_train, X_test, y_train, y_test\n",
        "\n",
        "    def tune_models(self, X_train, y_train):\n",
        "        \"\"\"Enhanced model tuning with regularization and meta-ensemble optimization\"\"\"\n",
        "        param_grids = {\n",
        "          'GradientBoost': {\n",
        "              'n_estimators': [100, 150],\n",
        "              'learning_rate': [0.05, 0.1],\n",
        "              'max_depth': [3, 4]\n",
        "          },\n",
        "          'RandomForest': {\n",
        "              'n_estimators': [100, 150],\n",
        "              'max_depth': [None, 10],\n",
        "              'min_samples_split': [2, 5]\n",
        "          }\n",
        "      }\n",
        "\n",
        "        models = {\n",
        "            'GradientBoost': GradientBoostingRegressor(random_state=42),\n",
        "            'RandomForest': RandomForestRegressor(random_state=42)\n",
        "        }\n",
        "\n",
        "        # Tune individual models first\n",
        "        for name, model in models.items():\n",
        "            print(f\"\\nTuning {name}...\")\n",
        "\n",
        "            grid_search = GridSearchCV(\n",
        "                estimator=model,\n",
        "                param_grid=param_grids[name],\n",
        "                cv=3,\n",
        "                scoring=['r2', 'neg_mean_squared_error'],\n",
        "                refit='r2',\n",
        "                n_jobs=-1,\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "            grid_search.fit(X_train, y_train)\n",
        "            self.best_models[name] = grid_search.best_estimator_\n",
        "            self.cv_results[name] = {\n",
        "                'best_params': grid_search.best_params_,\n",
        "                'best_score': grid_search.best_score_\n",
        "            }\n",
        "\n",
        "        # Create and optimize meta-ensemble\n",
        "        self._optimize_ensemble_weights(X_train, y_train)\n",
        "\n",
        "    def _optimize_ensemble_weights(self, X, y, n_trials=100):\n",
        "        \"\"\"Optimize ensemble weights using random search\"\"\"\n",
        "        print(\"\\nOptimizing ensemble weights...\")\n",
        "\n",
        "        best_score = float('-inf')\n",
        "        best_weights = None\n",
        "\n",
        "        # Initialize meta-ensemble\n",
        "        models_list = list(self.best_models.values())\n",
        "        self.meta_ensemble = MetaEnsemble(models_list)\n",
        "\n",
        "        # Random search for optimal weights\n",
        "        for _ in range(n_trials):\n",
        "            # Generate random weights that sum to 1\n",
        "            weights = np.random.dirichlet(np.ones(len(models_list)))\n",
        "            self.meta_ensemble.set_weights(weights)\n",
        "\n",
        "            # Evaluate using cross-validation\n",
        "            scores = cross_val_score(\n",
        "                self.meta_ensemble, X, y,\n",
        "                cv=5, scoring='neg_mean_squared_error'\n",
        "            )\n",
        "            mean_score = -scores.mean()  # Convert back to MSE\n",
        "\n",
        "            if mean_score > best_score:\n",
        "                best_score = mean_score\n",
        "                best_weights = weights\n",
        "\n",
        "        # Set the best weights\n",
        "        self.best_weights = best_weights\n",
        "        self.meta_ensemble.set_weights(best_weights)\n",
        "        print(f\"Best ensemble weights: {dict(zip(self.best_models.keys(), best_weights))}\")\n",
        "\n",
        "    def evaluate_models(self, X_train, X_test, y_train, y_test):\n",
        "        \"\"\"Evaluate individual models and meta-ensemble\"\"\"\n",
        "        results = {}\n",
        "\n",
        "        # Evaluate individual models\n",
        "        for name, model in self.best_models.items():\n",
        "            print(f\"\\n{name} Results:\")\n",
        "            results[name] = self._evaluate_single_model(\n",
        "                model, X_train, X_test, y_train, y_test\n",
        "            )\n",
        "\n",
        "        # Evaluate meta-ensemble\n",
        "        print(\"\\nMeta-Ensemble Results:\")\n",
        "        self.meta_ensemble.fit(X_train, y_train)\n",
        "        results['MetaEnsemble'] = self._evaluate_single_model(\n",
        "            self.meta_ensemble, X_train, X_test, y_train, y_test\n",
        "        )\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _evaluate_single_model(self, model, X_train, X_test, y_train, y_test):\n",
        "        \"\"\"Helper method to evaluate a single model\"\"\"\n",
        "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "        cv_scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='r2')\n",
        "\n",
        "        print(f\"Cross-validation R2 scores: {cv_scores}\")\n",
        "        print(f\"Mean CV R2: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "        y_train_pred = model.predict(X_train)\n",
        "        y_test_pred = model.predict(X_test)\n",
        "\n",
        "        metrics = self._calculate_metrics(\n",
        "            y_train, y_train_pred, y_test, y_test_pred, cv_scores\n",
        "        )\n",
        "\n",
        "        for metric, value in metrics.items():\n",
        "            print(f\"{metric}: {value}\")\n",
        "\n",
        "        return metrics\n",
        "\n",
        "    def _calculate_metrics(self, y_train, y_train_pred, y_test, y_test_pred, cv_scores):\n",
        "        \"\"\"Calculate comprehensive metrics\"\"\"\n",
        "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
        "        test_mae = mean_absolute_error(y_test, y_test_pred)\n",
        "        train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
        "        test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))\n",
        "        train_r2 = r2_score(y_train, y_train_pred)\n",
        "        test_r2 = r2_score(y_test, y_test_pred)\n",
        "\n",
        "        y_range = y_test.max() - y_test.min()\n",
        "        r2_percentage = max(0, test_r2 * 100)\n",
        "        mae_percentage = max(0, 100 * (1 - test_mae / y_range))\n",
        "        rmse_percentage = max(0, 100 * (1 - test_rmse / y_range))\n",
        "        overall_score = (r2_percentage + mae_percentage + rmse_percentage) / 3\n",
        "\n",
        "        return {\n",
        "            'Train MAE': train_mae,\n",
        "            'Test MAE': test_mae,\n",
        "            'Train RMSE': train_rmse,\n",
        "            'Test RMSE': test_rmse,\n",
        "            'Train R2': train_r2,\n",
        "            'Test R2': test_r2,\n",
        "            'CV R2 Mean': cv_scores.mean(),\n",
        "            'CV R2 Std': cv_scores.std(),\n",
        "            'R2 Performance': f\"{r2_percentage:.2f}%\",\n",
        "            'MAE Performance': f\"{mae_percentage:.2f}%\",\n",
        "            'RMSE Performance': f\"{rmse_percentage:.2f}%\",\n",
        "            'Overall Performance': f\"{overall_score:.2f}%\"\n",
        "        }\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions using the meta-ensemble\"\"\"\n",
        "        if self.meta_ensemble is None:\n",
        "            raise ValueError(\"Models haven't been trained yet!\")\n",
        "        return self.meta_ensemble.predict(X)"
      ],
      "metadata": {
        "id": "Kab9TrO8M4c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = BatterySOHPredictorTuned(df)\n",
        "X_train, X_test, y_train, y_test = predictor.prepare_features()\n",
        "predictor.tune_models(X_train, y_train)\n",
        "results = predictor.evaluate_models(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "jdhz1qd8NUig"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}